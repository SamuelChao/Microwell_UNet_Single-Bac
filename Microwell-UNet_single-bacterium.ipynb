{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYsylhjZuXkL"
   },
   "source": [
    "# UNet++ & Unet for microwell-DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFQkgbjWudM5"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPOqQGrFea6k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras.layers import Input, Add, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import callbacks\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "# from IPython.display import HTML\n",
    "# from base64 import b64encode\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional(Colab): mount google drive to colab workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2557,
     "status": "ok",
     "timestamp": 1716455845630,
     "user": {
      "displayName": "趙伯宣",
      "userId": "09648794267176348713"
     },
     "user_tz": -480
    },
    "id": "EcrweOHyZYjB",
    "outputId": "db2df9cb-4d5e-428c-a0e6-9823cd8df57e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set yout own directory\n",
    "os.chdir('/content/drive/MyDrive/*********/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test tensorflow GPU usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Constants\n",
    "BATCH_SIZE = 15\n",
    "BUFFER_SIZE = 1000\n",
    "IMG_SIZE = 128\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 1\n",
    "SEED = 123\n",
    "\n",
    "## Set Epochs **IMPORTANT**\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function: load image from source directory and return a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9K08avVrEWT"
   },
   "outputs": [],
   "source": [
    "# Function to load image from source directory and return a dictionary\n",
    "def parse_image(img_path: str) -> dict:\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "\n",
    "\n",
    "    mask_path = tf.strings.regex_replace(img_path,\"images\", \"masks\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"well\", \"mask\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "\n",
    "\n",
    "    bac_label = np.array([255, 255, 255])\n",
    "\n",
    "\n",
    "    # Convert to mask to binary mask\n",
    "    bac_label = np.array([255, 255, 255])\n",
    "    mask = tf.experimental.numpy.all(mask == bac_label, axis = 2)\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function: Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow function to rescale images to [0, 1]\n",
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function: Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tensorflow function to apply preprocessing transformations of training images\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.math.round(input_mask)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "# Tensorflow function to preprocess validation images\n",
    "@tf.function\n",
    "def load_image_val(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.math.round(input_mask)\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "# Tensorflow function to preprocess testing images\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "# def load_image_test(datapoint: dict, IMG_SIZE: int = 128) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.math.round(input_mask)\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function: display and save dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    # fig =  plt.subplots()\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\"debug_test/\" + 'display_sample_test.png', \n",
    "                    dpi=300, \n",
    "                    transparent=True, \n",
    "                    bbox_inches='tight'\n",
    "                    )\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset_preprocess(train_dataset):\n",
    "    # -- Train Dataset --#\n",
    "    train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def val_dataset_preprocess(val_dataset):\n",
    "    # -- Validation Dataset --#\n",
    "    val_dataset = val_dataset.map(load_image_test)\n",
    "    val_dataset = val_dataset.repeat()\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return val_dataset\n",
    "\n",
    "\n",
    "\n",
    "def test_dataset_preprocess(test_dataset):\n",
    "    #-- Testing Dataset --#\n",
    "    test_dataset = test_dataset.map(load_image_test)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function: Get dataset size of train, val, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_dataset_size(dataset_dir: str =  \"./dataset\"):\n",
    "    image_dir = join(dataset_dir, \"images\")\n",
    "    train_data_dir = image_dir\n",
    "\n",
    "    # Number of training examples\n",
    "    TRAINSET_SIZE = int(round(len(os.listdir(train_data_dir)) * 0.7))\n",
    "    print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
    "    VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
    "    print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
    "    TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
    "    print(f\"Number of Testing Examples: {TESTSET_SIZE}\")\n",
    "\n",
    "    dataset_size = {\"TRAINSET_SIZE\": TRAINSET_SIZE, \n",
    "                    \"VALIDSET_SIZE\": VALIDSET_SIZE, \n",
    "                    \"TESTSET_SIZE\": TESTSET_SIZE}\n",
    "    return dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function: get all datasets with images:masks pair and augmentations\n",
    "prepare train/val/test dataset with preprocessing from given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_all(dataset_dir: str =  \"./dataset\"):\n",
    "    # Load directories\n",
    "    # dataset_dir = \"./dataset\"\n",
    "    image_dir = join(dataset_dir, \"images\")\n",
    "    train_data_dir = image_dir\n",
    "\n",
    "    # Number of training examples\n",
    "    TRAINSET_SIZE = int(round(len(os.listdir(train_data_dir)) * 0.7))\n",
    "    print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
    "    VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
    "    print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
    "    TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
    "    print(f\"Number of Testing Examples: {TESTSET_SIZE}\")\n",
    "\n",
    "\n",
    "    ### Generate dataset variables\n",
    "    all_dataset = tf.data.Dataset.list_files(train_data_dir + \"/*.png\",  shuffle = False)\n",
    "    all_dataset = all_dataset.shuffle(BUFFER_SIZE, seed=SEED, reshuffle_each_iteration=False)\n",
    "    all_dataset = all_dataset.map(parse_image)\n",
    "\n",
    "\n",
    "    train_dataset = all_dataset.take(TRAINSET_SIZE + VALIDSET_SIZE)\n",
    "    val_dataset = train_dataset.skip(TRAINSET_SIZE)\n",
    "    train_dataset = train_dataset.take(TRAINSET_SIZE)\n",
    "    test_dataset = all_dataset.skip(TRAINSET_SIZE + VALIDSET_SIZE)\n",
    "\n",
    "\n",
    "    train_dataset = train_dataset_preprocess(train_dataset)\n",
    "    val_dataset = val_dataset_preprocess(val_dataset)\n",
    "    test_dataset = test_dataset_preprocess(test_dataset)\n",
    "\n",
    "    dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataloader cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "dataset = get_dataset_all(\"./dataset\")\n",
    "\n",
    "\n",
    "for image, mask in dataset['train'].take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "display_sample([sample_image[0], sample_mask[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le-DhjjgnP90"
   },
   "source": [
    "# Models: UNet++ & U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vTk15x3nWhY"
   },
   "source": [
    "## UNet++ Architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0t191QhQE_R"
   },
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   p = layers.Dropout(0.5)(p)\n",
    "   return f, p\n",
    "\n",
    "\n",
    "def upsample_block_part1(x, n_filters):\n",
    "   # upsample\n",
    "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "   return x\n",
    "\n",
    "def upsample_block_part2(x, n_filters):\n",
    "   # dropout\n",
    "   x = layers.Dropout(0.5)(x)\n",
    "   # Conv2D twice with ReLU activation\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x\n",
    "\n",
    "\n",
    "def build_unetPP_model():\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(128,128,3))\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    f00, p00 = downsample_block(inputs, 64)\n",
    "    f10, p10 = downsample_block(p00, 128)\n",
    "    f20, p20 = downsample_block(p10, 256)\n",
    "    f30, p30 = downsample_block(p20, 512)\n",
    "    bottleneck = double_conv_block(p30, 1024)\n",
    "\n",
    "    # decoders: expanding path - upsample\n",
    "    u01 = upsample_block_part1 (p00, 64)\n",
    "    u01 = layers.concatenate ([u01, f00])\n",
    "    u01 = upsample_block_part2 (u01, 64)\n",
    "\n",
    "    u11 = upsample_block_part1 (p10, 128)\n",
    "    u11 = layers.concatenate ([u11, f10])\n",
    "    u11 = upsample_block_part2 (u11, 128)\n",
    "\n",
    "    u21 = upsample_block_part1 (p20, 256)\n",
    "    u21 = layers.concatenate ([u21, f20])\n",
    "    u21 = upsample_block_part2 (u21, 256)\n",
    "\n",
    "    u31 = upsample_block_part1 (bottleneck, 512)\n",
    "    u31 = layers.concatenate ([u31, f30])\n",
    "    u31 = upsample_block_part2 (u31, 512)\n",
    "\n",
    "    u02 = upsample_block_part1 (u11, 64)\n",
    "    u02 = layers.concatenate ([u02, f00, u01])\n",
    "    u02 = upsample_block_part2 (u02, 64)\n",
    "\n",
    "    u12 = upsample_block_part1 (u21, 128)\n",
    "    u12 = layers.concatenate ([u12, f10, u11])\n",
    "    u12 = upsample_block_part2 (u12, 128)\n",
    "\n",
    "    u22 = upsample_block_part1 (u31, 256)\n",
    "    u22 = layers.concatenate([u22, f20, u21])\n",
    "    u22 = upsample_block_part2(u22, 256)\n",
    "\n",
    "    u03 = upsample_block_part1 (u12, 64)\n",
    "    u03 = layers.concatenate([u03, f00, u01, u02])\n",
    "    u03 = upsample_block_part2(u03, 64)\n",
    "\n",
    "    u13 = upsample_block_part1 (u22, 128)\n",
    "    u13 = layers.concatenate([u13, f10, u11, u12])\n",
    "    u13 = upsample_block_part2(u13, 128)\n",
    "\n",
    "    u04 = upsample_block_part1 (u13, 64)\n",
    "    u04 = layers.concatenate([u04, f00, u01, u02, u03])\n",
    "    u04 = upsample_block_part2(u04, 64)\n",
    "\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u04)\n",
    "    # unet model with Keras Functional API\n",
    "    unetPP_model = tf.keras.Model(inputs, outputs, name=\"UNetPP\")\n",
    "    return unetPP_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def double_conv_block(x, n_filters):\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   p = layers.Dropout(0.5)(p)\n",
    "   return f, p\n",
    "\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "   # upsample\n",
    "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "   # concatenate\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   # dropout\n",
    "   x = layers.Dropout(0.5)(x)\n",
    "   # Conv2D twice with ReLU activation\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x\n",
    "\n",
    "\n",
    "def build_unet_model():\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(128,128,3))\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model type: UNet++ or U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose Which DL model to train and perform single-bac well identification\n",
    "## Two options:\n",
    "## Option 1: 'UNetPP' \n",
    "## Option 2: 'UNet'\n",
    "\n",
    "model_name = 'UNetPP' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set result folder & build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'UNetPP':\n",
    "    unetPP_folder = 'UNetPP_result/'\n",
    "    result_folder = 'UNetPP_result/'\n",
    "    model = build_unetPP_model()\n",
    "    model.summary()\n",
    "elif model_name == 'UNet':\n",
    "    unetPP_folder = 'UNet_result/'\n",
    "    result_folder = 'UNet_result/'\n",
    "    model = build_unet_model()\n",
    "    model.summary()\n",
    "else:\n",
    "    raise Exception(\"Sorry, you do not choose the available DL model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2uCNt7hndus"
   },
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pn9ZtC97njaR"
   },
   "outputs": [],
   "source": [
    "## Optimization\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4, clipvalue=0.5)\n",
    "## metric: BinaryIoU\n",
    "b_iou = tf.keras.metrics.BinaryIoU(\n",
    "    target_class_ids=[1], threshold=0.5, name=None, dtype=None\n",
    ")\n",
    "## model compile\n",
    "model.compile(loss=BinaryCrossentropy(), optimizer=opt,  metrics=[b_iou])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Callback: define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.binary_io_u_values = []\n",
    "        self.val_losses = []\n",
    "        self.val_binary_io_u_values = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.binary_io_u_values.append(logs.get('binary_io_u'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_binary_io_u_values.append(logs.get('val_binary_io_u'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup custom callback in each iteration\n",
    "1. Add loss and IoU (learning progress) to lists\n",
    "2. save model checkpoint when val_loss improve\n",
    "3. update tensorboard log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_history = CustomHistory()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    result_folder + 'best_' + model_name +'_model.keras', \n",
    "    save_weights_only=True, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min')\n",
    "\n",
    "callbacks_list = [\n",
    "    custom_history, \n",
    "    checkpoint,\n",
    "    callbacks.TensorBoard(result_folder + 'log/', histogram_freq = -1)  \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbRDQ6d1oKqR"
   },
   "source": [
    "### Set hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1715578649197,
     "user": {
      "displayName": "趙伯宣",
      "userId": "09648794267176348713"
     },
     "user_tz": -480
    },
    "id": "Xaww5yy1oMxL",
    "outputId": "d879e7cd-2595-4597-e9ab-3d00ef6ecd5d"
   },
   "outputs": [],
   "source": [
    "## Set Epochs **IMPORTANT**\n",
    "EPOCHS = 300\n",
    "\n",
    "## Set Variables\n",
    "dataset_size = all_dataset_size(dataset_dir = \"./dataset\")\n",
    "TRAINSET_SIZE = dataset_size['TRAINSET_SIZE']\n",
    "VALIDSET_SIZE = dataset_size['VALIDSET_SIZE']\n",
    "TESTSET_SIZE = dataset_size['TESTSET_SIZE']\n",
    "\n",
    "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
    "VALIDATION_STEPS = VALIDSET_SIZE // BATCH_SIZE\n",
    "# print(TRAINSET_SIZE)\n",
    "# print(VALIDSET_SIZE)\n",
    "# print(BATCH_SIZE)\n",
    "# print(STEPS_PER_EPOCH)\n",
    "# print(VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1700379,
     "status": "ok",
     "timestamp": 1715580349574,
     "user": {
      "displayName": "趙伯宣",
      "userId": "09648794267176348713"
     },
     "user_tz": -480
    },
    "id": "NOn7pFjhoULl",
    "outputId": "e0d73d1c-63b9-404b-a660-5ecaa0ffe2da"
   },
   "outputs": [],
   "source": [
    "initial_time = time()\n",
    "\n",
    "\n",
    "# Model Training\n",
    "model.fit(dataset['train'], epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          validation_data=dataset['val'],\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "print('Finished Unet++ Training')\n",
    "print('Training time', time() - initial_time)\n",
    "model.save_weights(result_folder + f'epoch300_{model_name}_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNRVquHVqJvA"
   },
   "source": [
    "## (Optional) Validation set  show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 101876,
     "status": "error",
     "timestamp": 1715620278495,
     "user": {
      "displayName": "趙伯宣",
      "userId": "09648794267176348713"
     },
     "user_tz": -480
    },
    "id": "l4j8XzO-ofBd",
    "outputId": "22347419-f178-48ae-e139-0dbfe39ac90b"
   },
   "outputs": [],
   "source": [
    "#### Repeat for safety and reabiility #####################################################\n",
    "# Function to view the images from the directory\n",
    "def display_sample(display_list):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predict Map', 'Predict Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Function to create a mask out of network prediction\n",
    "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
    "    # Round to closest\n",
    "    pred_mask = tf.math.round(pred_mask)\n",
    "\n",
    "    # [IMG_SIZE, IMG_SIZE] -> [IMG_SIZE, IMG_SIZE, 1]\n",
    "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "\n",
    "# Function to show predictions\n",
    "def show_validation(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        # Predict and show image from input dataset\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display_sample([image[0], mask, pred_mask, create_mask(pred_mask)])\n",
    "\n",
    "            img = tf.keras.preprocessing.image.array_to_img(image[0])\n",
    "            img.save(result_folder + f'outputs/validate_{num}_well.png')\n",
    "\n",
    "            true_mask_img = tf.keras.preprocessing.image.array_to_img(mask)\n",
    "            true_mask_img.save(result_folder + f'outputs/validate_{num}_true_mask.png')\n",
    "\n",
    "            pred_map_img = tf.keras.preprocessing.image.array_to_img(pred_mask)\n",
    "            pred_map_img.save(result_folder + f'outputs/validate_{num}_predict_map.png')\n",
    "\n",
    "            pred_mask_img = tf.keras.preprocessing.image.array_to_img(create_mask(pred_mask))\n",
    "            pred_mask_img.save(result_folder + f'outputs/validate_{num}_predict_mask.png')\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Predict and show the sample image\n",
    "        inference = model.predict(sample_image)\n",
    "        display_sample([sample_image[0], sample_mask[0],\n",
    "                        inference[0]])\n",
    "\n",
    "        img = tf.keras.preprocessing.image.array_to_img(sample_image[0])\n",
    "        img.save(result_folder + f'outputs/validate_{num}_well.png')\n",
    "\n",
    "        true_mask_img = tf.keras.preprocessing.image.array_to_img(sample_mask[0])\n",
    "        true_mask_img.save(result_folder + f'outputs/validate_{num}_true_mask.png')\n",
    "\n",
    "        pred_mask_img = tf.keras.preprocessing.image.array_to_img(inference[0])\n",
    "        pred_mask_img.save(result_folder + f'outputs/validate_{num}_predict_mask.png')\n",
    "\n",
    "\n",
    "## Show validation image, true mask & predict mask\n",
    "show_validation(dataset['test'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Losses & IoU records in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss curve: Dataframe & Save CSV\n",
    "training_loss = custom_history.losses\n",
    "epochs_list = list(range(1, len(training_loss) + 1))\n",
    "df_tloss = pd.DataFrame({\"Epochs\": epochs_list, \"train_loss\" : training_loss})\n",
    "df_tloss.to_csv(unetPP_folder +'training_loss.csv', index=False)\n",
    "\n",
    "# Validate Loss curve: Dataframe & Save CSV\n",
    "\n",
    "val_losses = custom_history.val_losses\n",
    "df_vloss = pd.DataFrame({\"Epochs\": epochs_list, \"validate_loss\" : val_losses})\n",
    "df_vloss.to_csv(unetPP_folder + 'validate_loss.csv', index=False)\n",
    "\n",
    "\n",
    "# Training binaryIOU curve: Dataframe & Save CSV\n",
    "binary_io_u_values = custom_history.binary_io_u_values\n",
    "# print(binary_io_u_values)\n",
    "df_tbiou = pd.DataFrame({\"Epochs\": epochs_list, \"train_bIOU\" : binary_io_u_values})\n",
    "df_tbiou.to_csv(unetPP_folder + 'training_bIOU.csv', index=False)\n",
    "\n",
    "\n",
    "# Validation binaryIOU curve: Dataframe & Save CSV\n",
    "val_binary_io_u_values = custom_history.val_binary_io_u_values\n",
    "# print(val_binary_io_u_values)\n",
    "df_vbiou = pd.DataFrame({\"Epochs\": epochs_list, \"val_bIOU\" : val_binary_io_u_values})\n",
    "df_vbiou.to_csv(unetPP_folder + 'validate_bIOU.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Learning curve figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs', fontsize=12)\n",
    "ax1.set_ylabel('Loss', color=color, fontsize=12)\n",
    "ax1.plot(df_tloss[\"Epochs\"], df_tloss[\"train_loss\"], '-', label='Training Loss', color=color)\n",
    "ax1.plot(df_vloss[\"Epochs\"], df_vloss[\"validate_loss\"], '-', alpha = 0.5, label='Validation Loss', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_ylim([-0.01, 0.13])\n",
    "ax1.set_box_aspect(0.75)\n",
    "\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('IoU', color=color, fontsize=12)  # we already handled the x-label with ax1\n",
    "ax2.plot(df_tbiou[\"Epochs\"], df_tbiou[\"train_bIOU\"], '-', label='Training IoU', color=color)\n",
    "ax2.plot(df_vbiou[\"Epochs\"], df_vbiou[\"val_bIOU\"], '-', alpha = 0.5, label='Validation IoU', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2.set_ylim([-0.1, 0.9])\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=9)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(result_folder + 'learning_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rWuSOxC2KfO"
   },
   "source": [
    "# Model Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load checkpoint model weights at epoch300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model type\n",
    "if model_name == 'UNetPP':\n",
    "    model = build_unetPP_model()\n",
    "    # result_folder = 'UNetPP_result/'\n",
    "elif model_name == 'UNet':\n",
    "    model = build_unet_model()\n",
    "    # result_folder = 'UNet_result/'\n",
    "else:\n",
    "    raise Exception(\"Sorry, you do not choose the available DL model type\")\n",
    "\n",
    "\n",
    "## compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4, clipvalue=0.5)\n",
    "m_iou = tf.keras.metrics.BinaryIoU(\n",
    "    target_class_ids=[1], threshold=0.5, name=None, dtype=None\n",
    ")\n",
    "model.compile(loss=BinaryCrossentropy(), optimizer=opt,  metrics=[m_iou])\n",
    "\n",
    "## load checkpoint model weight\n",
    "model.load_weights(result_folder + f'epoch300_{model_name}_model.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Time of test-set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_time = time()\n",
    "\n",
    "for image, mask in dataset['test']:\n",
    "    pred_mask = model.predict(image)\n",
    "\n",
    "print(f'Finished {model_name} Testing')\n",
    "print('Testing time', time() - initial_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single_Bac Microwell identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microwell bacteria-count inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mask over image\n",
    "def weighted_img(img, initial_img, α=1., β=0.5, γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "# Function to process an individual image and it's mask\n",
    "def process_image_mask(image, mask):\n",
    "    # Round to closest\n",
    "    mask = tf.math.round(mask)\n",
    "\n",
    "    # Convert to mask image\n",
    "    zero_image = np.zeros_like(mask)\n",
    "    mask = np.dstack((mask, zero_image, zero_image))\n",
    "    mask = np.asarray(mask, np.float32)\n",
    "\n",
    "    # Convert to image image\n",
    "    image = np.asarray(image, np.float32)\n",
    "\n",
    "    # Get the final image\n",
    "    final_image = weighted_img(mask, image)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate bacteria number inside microwell\n",
    "def bacteria_count(mask):\n",
    "    mask = mask = tf.math.round(mask)\n",
    "    mask_img = tf.keras.preprocessing.image.array_to_img(mask)\n",
    "    img2 = cv2.cvtColor(np.asarray(mask_img), cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    bacNum = len(cnts)\n",
    "    return bacNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the images as a plot\n",
    "def save_predict_sample(display_list, index, result_folder):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(result_folder + f'outputs/{index}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    image_array = display_list[0]\n",
    "    true_mask_array = display_list[1]\n",
    "    pred_mask_array = display_list[2]\n",
    "\n",
    "    img = tf.keras.preprocessing.image.array_to_img(image)\n",
    "    img.save(result_folder + f'outputs/{index}_well.png')\n",
    "    true_mask_img = tf.keras.preprocessing.image.array_to_img(true_mask_array)\n",
    "    true_mask_img.save(result_folder + f'outputs/{index}_true.png')\n",
    "    pred_mask_img = tf.keras.preprocessing.image.array_to_img(pred_mask_array)\n",
    "    pred_mask_img.save(result_folder + f'outputs/{index}_predict.png')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testset images bacteria count prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save predictions\n",
    "def get_predictions(dataset, result_folder):\n",
    "    # Predict and save image the from input dataset\n",
    "    True_Counts = []\n",
    "    Pred_Counts = []\n",
    "    index = 0\n",
    "    for batch_image, batch_mask in dataset:\n",
    "        for image, mask in zip(batch_image, batch_mask):\n",
    "            print(f\"Processing image : {index}\")\n",
    "            pred_mask = model.predict(tf.expand_dims(image, axis = 0))\n",
    "\n",
    "            true_bacNum = bacteria_count(mask)\n",
    "            True_Counts.append(true_bacNum)\n",
    "            print(\"True Bac-Num:    \", true_bacNum, \"\\n\")\n",
    "\n",
    "            pred_bacNum = bacteria_count(pred_mask[0])\n",
    "            Pred_Counts.append(pred_bacNum)\n",
    "            print(\"Predict Bac-Num: \", pred_bacNum, \"\\n\")\n",
    "\n",
    "            display_list = [image, \n",
    "                            process_image_mask(image, mask), \n",
    "                            process_image_mask(image, pred_mask[0])\n",
    "                            ]\n",
    "            \n",
    "            save_predict_sample(display_list, \n",
    "                                index, \n",
    "                                result_folder)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    num_result = pd.DataFrame({'True_Number': True_Counts, \n",
    "                               'Predict_Number': Pred_Counts})\n",
    "    num_result.to_csv(\n",
    "                result_folder + 'Number_Result.csv', \n",
    "                index= False , \n",
    "                header = True\n",
    "                )\n",
    "\n",
    "    return True_Counts, Pred_Counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Counts, Pred_Counts = get_predictions(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacteria-counts accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_calculator(predict, label):\n",
    "    total = len(Pred_Counts)\n",
    "    correct = 0\n",
    "    for i in range(total):\n",
    "        if (predict[i] == label[i]):\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "    return round(100 * correct / total, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_acc = acc_calculator(Pred_Counts, True_Counts)\n",
    "print(\"Counts Accuracy: \", num_acc)\n",
    "\n",
    "num_acc_df = pd.DataFrame({'Number_Accuracy': [num_acc]})\n",
    "num_acc_df.to_csv(result_folder + 'Number_Accuracy.csv', index= False , header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacteria-counts confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Confusion Matrix\n",
    "def get_confusion_matrix(True_Counts, Pred_Counts, model_name, result_folder):\n",
    "\n",
    "    conf = confusion_matrix(True_Counts, Pred_Counts, normalize='false')\n",
    "    nor_conf = confusion_matrix(True_Counts, Pred_Counts,normalize='true')\n",
    "\n",
    "    conf_df = pd.DataFrame(conf)\n",
    "    conf_df.to_csv(result_folder + 'Number_Conf.csv', \n",
    "                  index= False , \n",
    "                  header = False)\n",
    "\n",
    "    nor_conf_df = pd.DataFrame(nor_conf)  \n",
    "    nor_conf_df.to_csv(result_folder + 'Number_Conf_Nor.csv', \n",
    "                       index= False , \n",
    "                       header = False)\n",
    "\n",
    "    return conf, nor_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf, nor_conf, model_name, result_folder):\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "    # Number confusion matrix\n",
    "    conf = np.around(conf, 2)\n",
    "    conf_disp = ConfusionMatrixDisplay(confusion_matrix=conf)\n",
    "    conf_disp.plot(cmap ='gist_yarg', colorbar=False)\n",
    "    plt.xlabel('Predicted Number', fontsize=12)\n",
    "    plt.ylabel('True Number', fontsize=12)\n",
    "\n",
    "    plt.savefig(result_folder + 'Number_Conf.png',\n",
    "                 dpi=300, \n",
    "                 transparent=True, \n",
    "                 bbox_inches='tight')\n",
    "    \n",
    "    # Normalizaed confusion matrix\n",
    "        \n",
    "    nor_conf = np.around(nor_conf, 2)\n",
    "    nor_disp = ConfusionMatrixDisplay(confusion_matrix=nor_conf)\n",
    "    nor_disp.plot(cmap ='gist_yarg', colorbar=False)\n",
    "    plt.xlabel('Predicted Number', fontsize=12)\n",
    "    plt.ylabel('True Number', fontsize=12)\n",
    "\n",
    "    plt.savefig(result_folder + 'Number_Conf_Nor.png', \n",
    "                dpi=300, \n",
    "                transparent=True, \n",
    "                bbox_inches='tight')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf, nor_conf = get_confusion_matrix(\n",
    "    True_Counts, Pred_Counts, model_name, result_folder)\n",
    "\n",
    "plot_confusion_matrix(conf, nor_conf, model_name, result_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microwell Single-bacterium inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert bacteria-count to binary single-bacterium class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_singlebac(True_Counts, Pred_Counts, result_folder):\n",
    "    true_single = np.array(True_Counts)\n",
    "    true_single[true_single != 1] = 0\n",
    "\n",
    "    pred_single = np.array(Pred_Counts)\n",
    "    pred_single[pred_single != 1] = 0\n",
    "\n",
    "    single_result = pd.DataFrame(\n",
    "        {'True_Single': true_single, 'Pred_Single': pred_single})\n",
    "    \n",
    "    single_result.to_csv(result_folder + 'Single_Result.csv', \n",
    "                         index= False , \n",
    "                         header = True)\n",
    "    \n",
    "    return true_single, pred_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_single, pred_single = convert_singlebac(\n",
    "                                    True_Counts, \n",
    "                                    Pred_Counts, \n",
    "                                    result_folder\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Bacterium accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_calculator(predict, label):\n",
    "    total = len(Pred_Counts)\n",
    "    correct = 0\n",
    "    for i in range(total):\n",
    "        if (predict[i] == label[i]):\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "    return round(100 * correct / total, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_single = acc_calculator(pred_single, true_single)\n",
    "print('Single_Accuracy: ', acc_single)\n",
    "\n",
    "acc_single_df = pd.DataFrame({'Single_Accuracy': [acc_single]})\n",
    "acc_single_df.to_csv(result_folder + 'Single_Accuracy.csv', \n",
    "                     index= False , \n",
    "                     header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Bacterium confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Single-Bacterium Confusion Matrix\n",
    "def get_singlebac_confusion_matrix(true_single, pred_single, model_name, result_folder):\n",
    "\n",
    "    conf = confusion_matrix(true_single, pred_single, normalize='false')\n",
    "    nor_conf = confusion_matrix(true_single, pred_single, normalize='true')\n",
    "\n",
    "    conf_df = pd.DataFrame(conf)\n",
    "    conf_df.to_csv(result_folder + 'Single_Conf.csv', \n",
    "                  index= False , \n",
    "                  header = False)\n",
    "\n",
    "    nor_conf_df = pd.DataFrame(nor_conf)  \n",
    "    nor_conf_df.to_csv(result_folder + 'Single_Conf_Nor.csv', \n",
    "                       index= False , \n",
    "                       header = False)\n",
    "\n",
    "    return conf, nor_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_singlebac_confusion_matrix(conf, nor_conf, model_name, result_folder):\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    singleBac_labels = np.array(['Non-Single', 'Single-Bacterium'])\n",
    "\n",
    "    ## Plot Single-Bac confusion matrix \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf, display_labels = singleBac_labels)\n",
    "    disp.plot(cmap ='gist_yarg', colorbar=False)\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.yticks(rotation=90, ha='right', fontsize = 10, \n",
    "               rotation_mode='default', va=\"center\")\n",
    "    plt.xlabel('Prediction', fontsize=12)\n",
    "    plt.ylabel('True', fontsize=12)\n",
    "    plt.savefig(result_folder + 'Single_Conf.png',\n",
    "                 dpi=300, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    ## Plot Normalized Single-Bac confusion matrix \n",
    "    nor_conf = np.around(nor_conf, 2)\n",
    "    nor_disp = ConfusionMatrixDisplay(confusion_matrix=nor_conf, display_labels = singleBac_labels)\n",
    "    nor_disp.plot(cmap ='gist_yarg', colorbar=False)\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.yticks(rotation=90, ha='right', fontsize = 10, \n",
    "               rotation_mode='default', va=\"center\")\n",
    "    plt.xlabel('Prediction', fontsize=12)\n",
    "    plt.ylabel('True', fontsize=12)\n",
    "    plt.savefig(result_folder + 'Single_Conf_Nor.png', \n",
    "                dpi=300, transparent=True, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf, nor_conf = get_singlebac_confusion_matrix(\n",
    "    true_single, pred_single, model_name, result_folder)\n",
    "\n",
    "plot_singlebac_confusion_matrix(conf, nor_conf, model_name, result_folder)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4ILrYrMxjB3G",
    "ydha32EiQow9",
    "-lDPiJ25QIVm",
    "Cy9SYxVvkzdu",
    "Ef5WnRtwfH0Z",
    "r2DqKRkYdTe1",
    "dGp4r0Irflx1",
    "yTBPbQRpBrRZ",
    "qsoZ0GnBBtLW",
    "c0WsyuQZOIVD",
    "sty4zes7t1sG"
   ],
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1WI8lNKBjNots1fkGuZSD5EhAIgCfIeQb",
     "timestamp": 1716179770316
    },
    {
     "file_id": "1_0-ZlwDJxfZyIUkW-I6thYKswNDJAlhn",
     "timestamp": 1715574364122
    },
    {
     "file_id": "1llV4C9zex1J_yonAniRRg7F2tpzCg-RV",
     "timestamp": 1715484157256
    },
    {
     "file_id": "1Dug9GORarIYahsqHxVXKoc0ZJ9VKmNhD",
     "timestamp": 1715431625895
    },
    {
     "file_id": "1xAZAu-UHwyl0YHOs8ZbPZBqBVu3_CIf9",
     "timestamp": 1715328725099
    },
    {
     "file_id": "1OeM3iKoWX3IfbJI89DK-YVgh3mrl1f8V",
     "timestamp": 1715328656842
    },
    {
     "file_id": "1Ix1oWYEDczPZ0T3EpgZI2-Y5BTBKZrVx",
     "timestamp": 1714540711235
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
